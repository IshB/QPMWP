{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "\n",
    "Deadline: 30.04.2025 12:00 CET\n",
    "\n",
    "<Add your name, student-id and emal address>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites: Library imports, data load and initialization of the backtest service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "from typing import Optional\n",
    "\n",
    "# Third party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Add the project root directory to Python path\n",
    "project_root = os.path.dirname(os.path.dirname(os.getcwd()))   #<Change this path if needed>\n",
    "src_path = os.path.join(project_root, 'qpmwp-course\\\\src')    #<Change this path if needed>\n",
    "sys.path.append(project_root)\n",
    "sys.path.append(src_path)\n",
    "\n",
    "# Local modules imports\n",
    "from helper_functions import load_data_spi, load_pickle\n",
    "from estimation.covariance import Covariance\n",
    "from estimation.expected_return import ExpectedReturn\n",
    "from optimization.optimization import Optimization, Objective, MeanVariance\n",
    "from optimization.optimization_data import OptimizationData\n",
    "from optimization.constraints import Constraints\n",
    "from backtesting.backtest_item_builder_classes import (\n",
    "    SelectionItemBuilder,\n",
    "    OptimizationItemBuilder,\n",
    ")\n",
    "from backtesting.backtest_item_builder_functions import (\n",
    "    bibfn_selection_min_volume,\n",
    "    bibfn_selection_gaps,\n",
    "    bibfn_return_series,\n",
    "    bibfn_budget_constraint,\n",
    "    bibfn_box_constraints,\n",
    "    bibfn_size_dependent_upper_bounds,\n",
    ")\n",
    "from backtesting.backtest_data import BacktestData\n",
    "from backtesting.backtest_service import BacktestService\n",
    "from backtesting.backtest import Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m path_to_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# <change this to your path to data>\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load market and jkp data from parquet files\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m market_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpath_to_data\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mmarket_data.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Instantiate the BacktestData class\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# and set the market data and jkp data as attributes\u001b[39;00m\n\u001b[0;32m      9\u001b[0m data \u001b[38;5;241m=\u001b[39m BacktestData()\n",
      "File \u001b[1;32mc:\\Users\\IAB\\OneDrive\\CODE\\QPMP\\Assignment_1\\qpmwp-course\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:651\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;129m@doc\u001b[39m(storage_options\u001b[38;5;241m=\u001b[39m_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_parquet\u001b[39m(\n\u001b[0;32m    500\u001b[0m     path: FilePath \u001b[38;5;241m|\u001b[39m ReadBuffer[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    509\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m    510\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03m    Load a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[0;32m    512\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;124;03m    1    4    9\u001b[39;00m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 651\u001b[0m     impl \u001b[38;5;241m=\u001b[39m \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    653\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_nullable_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m    654\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    655\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_nullable_dtypes\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and will be removed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    656\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min a future version.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    657\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\IAB\\OneDrive\\CODE\\QPMP\\Assignment_1\\qpmwp-course\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:67\u001b[0m, in \u001b[0;36mget_engine\u001b[1;34m(engine)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m     65\u001b[0m             error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(err)\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find a usable engine; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtried using: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfastparquet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA suitable version of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow or fastparquet is required for parquet \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupport.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to import the above resulted in these errors:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_msgs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     75\u001b[0m     )\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PyArrowImpl()\n",
      "\u001b[1;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "path_to_data = 'data'  # <change this to your path to data>\n",
    "\n",
    "# Load market and jkp data from parquet files\n",
    "market_data = pd.read_parquet(path = f'{path_to_data}market_data.parquet')\n",
    "\n",
    "# Instantiate the BacktestData class\n",
    "# and set the market data and jkp data as attributes\n",
    "data = BacktestData()\n",
    "data.market_data = market_data\n",
    "data.bm_series = load_data_spi(path='../data/')  # <change this if necessary>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rebalancing dates\n",
    "n_days = 21*3\n",
    "market_data_dates = market_data.index.get_level_values('date').unique().sort_values(ascending=True)\n",
    "rebdates = market_data_dates[market_data_dates > '2015-01-01'][::n_days].strftime('%Y-%m-%d').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the selection item builders.\n",
    "selection_item_builders = {\n",
    "    'gaps': SelectionItemBuilder(\n",
    "        bibfn = bibfn_selection_gaps,\n",
    "        width = 252*3,\n",
    "        n_days = 10,\n",
    "    ),\n",
    "    'min_volume': SelectionItemBuilder(\n",
    "        bibfn = bibfn_selection_min_volume,\n",
    "        width = 252,\n",
    "        min_volume = 500_000,\n",
    "        agg_fn = np.median,\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Define the optimization item builders.\n",
    "optimization_item_builders = {\n",
    "    'return_series': OptimizationItemBuilder(\n",
    "        bibfn = bibfn_return_series,\n",
    "        width = 252*3,\n",
    "        fill_value = 0,\n",
    "    ),\n",
    "    'budget_constraint': OptimizationItemBuilder(\n",
    "        bibfn = bibfn_budget_constraint,\n",
    "        budget = 1,\n",
    "    ),\n",
    "    'box_constraints': OptimizationItemBuilder(\n",
    "        bibfn = bibfn_box_constraints,\n",
    "        upper = 0.1,\n",
    "    ),\n",
    "    'size_dep_upper_bounds': OptimizationItemBuilder(\n",
    "        bibfn = bibfn_size_dependent_upper_bounds,\n",
    "        small_cap = {'threshold': 300_000_000, 'upper': 0.02},\n",
    "        mid_cap = {'threshold': 1_000_000_000, 'upper': 0.05},\n",
    "        large_cap = {'threshold': 10_000_000_000, 'upper': 0.1},\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Initialize the backtest service\n",
    "bs = BacktestService(\n",
    "    data = data,\n",
    "    selection_item_builders = selection_item_builders,\n",
    "    optimization_item_builders = optimization_item_builders,\n",
    "    rebdates = rebdates,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Maximum Sharpe Ratio Portfolio\n",
    "\n",
    "a) \n",
    "\n",
    "(6 points)\n",
    "\n",
    "Complete the `MaxSharpe` class below by implementing your its methods `set_objective` and `solve`.\n",
    "The `solve` method should implement an iterative algorithm that quickly approximates the \"true\" maximimum Sharpe ratio portfolio (given the estimates of mean and covariance). This approximation should be done by repeatedly solving a mean-variance optimization problem, where the risk aversion parameter (which scales the covariance matrix) is adjusted in each iteration. The algorithm should terminate after a maximum of 10 iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxSharpe(Optimization):\n",
    "\n",
    "    def __init__(self,\n",
    "                 constraints: Optional[Constraints] = None,\n",
    "                 covariance: Optional[Covariance] = None,\n",
    "                 expected_return: Optional[ExpectedReturn] = None,\n",
    "                 **kwargs) -> None:\n",
    "        super().__init__(\n",
    "            constraints=constraints,\n",
    "            **kwargs,\n",
    "        )\n",
    "        self.covariance = Covariance() if covariance is None else covariance\n",
    "        self.expected_return = ExpectedReturn() if expected_return is None else expected_return\n",
    "\n",
    "    def set_objective(self, optimization_data: OptimizationData) -> None:\n",
    "        #<your code here>\n",
    "        return None\n",
    "\n",
    "    def solve(self) -> None:\n",
    "        #<your code here>\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) \n",
    "\n",
    "(2 points)\n",
    "\n",
    "Provide a theoretical or empirical justification that your algorithm converges to the true maximum Sharpe ratio portfolio for the given coefficients of mean and covariance.\n",
    "Hint: If you want to provide an empirical justification, you can perform an optimization for a single point in time by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs.optimization = MaxSharpe(\n",
    "#     covariance=Covariance(method='pearson'),\n",
    "#     expected_return=ExpectedReturn(method='geometric'),\n",
    "#     solver_name='cvxopt',  # <change this to your preferred solver>\n",
    "#     #<add any other parameters you need, e.g., number of iterations, tolerance, etc.>\n",
    "# )\n",
    "# bs.prepare_rebalancing('2015-01-02')\n",
    "# bs.optimization.set_objective(bs.optimization_data)\n",
    "# bs.optimization.solve()\n",
    "# bs.optimization.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Backtest MaxSharpe with Turnover Penalty\n",
    "\n",
    "(5 points)\n",
    "\n",
    "Calibrate the turnover penalty parameter such that the backtest of the MaxSharpe strategy displays an annual turnover of roughly 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the backtest service with a MaxSharpe optimization object\n",
    "bs.optimization = MaxSharpe(\n",
    "    covariance=Covariance(method='pearson'),\n",
    "    expected_return=ExpectedReturn(method='geometric'),\n",
    "    solver_name='cvxopt',    # <change this to your preferred solver>\n",
    "    turnover_penalty=None,   # <change this>\n",
    ")\n",
    "\n",
    "# Instantiate the backtest object\n",
    "bt_ms = Backtest()\n",
    "\n",
    "# Run the backtest\n",
    "bt_ms.run(bs = bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simulation and Descriptive Statistics\n",
    "\n",
    "(3 points)\n",
    "\n",
    "- Simulate the portfolio returns from your MaxSharpe backtest. Use fixed costs of 1% and variable costs of 0.3%.\n",
    "- Plot the cumulated returns of the MaxSharpe strategy together with those of the SPI Index.\n",
    "- Plot the turnover of your MaxSharpe strategy over time.\n",
    "- Print the annualized turnover (computed as the average turnover over the backtest multiplied by the number of rebalancing per year) for your MaxSharpe strategy.\n",
    "- Create and print a table with descriptive performance statistics for your MaxSharpe strategy and the SPI Index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<your code here>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
